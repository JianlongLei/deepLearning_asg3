{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T21:46:46.242008Z",
     "start_time": "2024-12-13T21:46:41.634269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Part 3: Variable Resolution Classifier\n",
    "class VariableResCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, num_filters=64, pooling=\"max\"):\n",
    "        super(VariableResCNN, self).__init__()\n",
    "        self.pooling = pooling\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, num_filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.AdaptiveMaxPool2d(1) if pooling == \"max\" else nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.fc = nn.Linear(num_filters, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Data Preparation for Variable Resolution Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Assuming variable resolution MNIST dataset is downloaded and organized\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "class VariableResolutionMNIST(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "        for label in range(10):\n",
    "            filepaths = glob(f\"{root}/{label}/*.png\")\n",
    "            self.files.extend(filepaths)\n",
    "            self.labels.extend([label] * len(filepaths))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.files[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def get_data_loaders(data_dir, batch_size=32):\n",
    "    \"\"\"Prepare data loaders for training, validation, and testing.\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)\n",
    "    test_data = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=transform)\n",
    "\n",
    "    train_size = len(train_data) - 10000\n",
    "    val_size = 10000\n",
    "    traindata, valdata = random_split(train_data, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    trainloader = DataLoader(traindata, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    valloader = DataLoader(valdata, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    testloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    return trainloader, valloader, testloader\n",
    "\n",
    "trainloader, valloader, testloader = get_data_loaders(data_dir = 'data/mnist-varres')\n",
    "\n",
    "data_loaders = {\n",
    "    \"train\": trainloader,\n",
    "    \"val\": valloader,\n",
    "    \"test\": testloader\n",
    "}\n",
    "\n",
    "# Training Loop\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, device, num_epochs=10):\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders['train'].dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloaders['val']:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_loss /= len(dataloaders['val'].dataset)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "# Initialize Model and Experiment\n",
    "results = []\n",
    "pooling_methods = [\"max\", \"mean\"]\n",
    "num_filters_list = [32, 48, 64]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for pooling in pooling_methods:\n",
    "    for num_filters in num_filters_list:\n",
    "        print(f\"\\nTesting with Pooling: {pooling}, Num Filters: {num_filters}\")\n",
    "        model = VariableResCNN(num_classes=10, num_filters=num_filters, pooling=pooling).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        history = train_model(model, data_loaders, criterion, optimizer, device, num_epochs=5)\n",
    "\n",
    "        torch.save(model.state_dict(), f\"variable_res_cnn_{pooling}_{num_filters}.pth\")\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(history['train_loss'], label='Train Loss')\n",
    "        plt.plot(history['val_loss'], label='Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.title(f'Loss over Epochs ({pooling}, {num_filters})')\n",
    "        plt.savefig(f'loss_{pooling}_{num_filters}.png')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "        plt.legend()\n",
    "        plt.title(f'Validation Accuracy ({pooling}, {num_filters})')\n",
    "        plt.savefig(f'accuracy_{pooling}_{num_filters}.png')\n",
    "\n",
    "        results.append({\n",
    "            \"pooling\": pooling,\n",
    "            \"num_filters\": num_filters,\n",
    "            \"val_acc\": history['val_acc'][-1]\n",
    "        })\n",
    "\n",
    "# Display Results\n",
    "for result in results:\n",
    "    print(f\"Pooling: {result['pooling']}, Num Filters: {result['num_filters']}, Final Val Acc: {result['val_acc']:.4f}\")\n"
   ],
   "id": "70d1277a0ec73113",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with Pooling: max, Num Filters: 32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 212, in collate\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 272, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: stack expects each tensor to be equal size, but got [3, 32, 32] at entry 0 and [3, 64, 64] at entry 1\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[39], line 161\u001B[0m\n\u001B[0;32m    158\u001B[0m model \u001B[38;5;241m=\u001B[39m VariableResCNN(num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, num_filters\u001B[38;5;241m=\u001B[39mnum_filters, pooling\u001B[38;5;241m=\u001B[39mpooling)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m    159\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m)\n\u001B[1;32m--> 161\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_loaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    163\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(model\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvariable_res_cnn_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpooling\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_filters\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    165\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure()\n",
      "Cell \u001B[1;32mIn[39], line 106\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, dataloaders, criterion, optimizer, device, num_epochs)\u001B[0m\n\u001B[0;32m    103\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m    104\u001B[0m running_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m--> 106\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m inputs, labels \u001B[38;5;129;01min\u001B[39;00m dataloaders[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[0;32m    107\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m    109\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1465\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1463\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1464\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[idx]\n\u001B[1;32m-> 1465\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   1489\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[0;32m   1490\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[1;32m-> 1491\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1492\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\_utils.py:715\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    711\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    712\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[0;32m    713\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[0;32m    714\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 715\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 212, in collate\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 272, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: stack expects each tensor to be equal size, but got [3, 32, 32] at entry 0 and [3, 64, 64] at entry 1\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T21:49:32.840379Z",
     "start_time": "2024-12-13T21:49:32.788217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "# Part 3: Variable Resolution Classifier\n",
    "class VariableResCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, num_filters=64, pooling=\"max\"):\n",
    "        super(VariableResCNN, self).__init__()\n",
    "        self.pooling = pooling\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, num_filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.AdaptiveMaxPool2d(1) if pooling == \"max\" else nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.fc = nn.Linear(num_filters, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Data Preparation for Variable Resolution Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "class VariableResolutionMNIST(Dataset):\n",
    "    def __init__(self, root, transform=None, resize_to=(32, 32)):\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        self.resize_to = resize_to\n",
    "\n",
    "        for label in range(10):\n",
    "            filepaths = glob(f\"{root}/{label}/*.png\")\n",
    "            self.files.extend(filepaths)\n",
    "            self.labels.extend([label] * len(filepaths))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.files[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "\n",
    "        if self.resize_to is not None:\n",
    "            image = image.resize(self.resize_to)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Load Data\n",
    "resize_resolution = (64, 64)  # Resize all images to 64x64 for uniformity\n",
    "train_data = VariableResolutionMNIST(\"./mnist-varres/train\", transform=transform, resize_to=resize_resolution)\n",
    "val_data = VariableResolutionMNIST(\"./mnist-varres/test\", transform=transform, resize_to=resize_resolution)\n",
    "\n",
    "data_loaders = {\n",
    "    \"train\": DataLoader(train_data, batch_size=16, shuffle=True),\n",
    "    \"val\": DataLoader(val_data, batch_size=16, shuffle=False)\n",
    "}\n",
    "\n",
    "# Training Loop\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, device, num_epochs=10):\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders['train'].dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloaders['val']:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_loss /= len(dataloaders['val'].dataset)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "# Initialize Model and Experiment\n",
    "results = []\n",
    "pooling_methods = [\"max\", \"mean\"]\n",
    "num_filters_list = [32, 64, 128]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for pooling in pooling_methods:\n",
    "    for num_filters in num_filters_list:\n",
    "        print(f\"\\nTesting with Pooling: {pooling}, Num Filters: {num_filters}\")\n",
    "        model = VariableResCNN(num_classes=10, num_filters=num_filters, pooling=pooling).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        history = train_model(model, data_loaders, criterion, optimizer, device, num_epochs=5)\n",
    "\n",
    "        torch.save(model.state_dict(), f\"variable_res_cnn_{pooling}_{num_filters}.pth\")\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(history['train_loss'], label='Train Loss')\n",
    "        plt.plot(history['val_loss'], label='Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.title(f'Loss over Epochs ({pooling}, {num_filters})')\n",
    "        plt.savefig(f'loss_{pooling}_{num_filters}.png')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "        plt.legend()\n",
    "        plt.title(f'Validation Accuracy ({pooling}, {num_filters})')\n",
    "        plt.savefig(f'accuracy_{pooling}_{num_filters}.png')\n",
    "\n",
    "        results.append({\n",
    "            \"pooling\": pooling,\n",
    "            \"num_filters\": num_filters,\n",
    "            \"val_acc\": history['val_acc'][-1]\n",
    "        })\n",
    "\n",
    "# Display Results\n",
    "for result in results:\n",
    "    print(f\"Pooling: {result['pooling']}, Num Filters: {result['num_filters']}, Final Val Acc: {result['val_acc']:.4f}\")\n"
   ],
   "id": "4e1420b3e95dd7a4",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[40], line 74\u001B[0m\n\u001B[0;32m     70\u001B[0m train_data \u001B[38;5;241m=\u001B[39m VariableResolutionMNIST(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./mnist-varres/train\u001B[39m\u001B[38;5;124m\"\u001B[39m, transform\u001B[38;5;241m=\u001B[39mtransform, resize_to\u001B[38;5;241m=\u001B[39mresize_resolution)\n\u001B[0;32m     71\u001B[0m val_data \u001B[38;5;241m=\u001B[39m VariableResolutionMNIST(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./mnist-varres/test\u001B[39m\u001B[38;5;124m\"\u001B[39m, transform\u001B[38;5;241m=\u001B[39mtransform, resize_to\u001B[38;5;241m=\u001B[39mresize_resolution)\n\u001B[0;32m     73\u001B[0m data_loaders \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m---> 74\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m,\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m\"\u001B[39m: DataLoader(val_data, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     76\u001B[0m }\n\u001B[0;32m     78\u001B[0m \u001B[38;5;66;03m# Training Loop\u001B[39;00m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_model\u001B[39m(model, dataloaders, criterion, optimizer, device, num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:376\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n\u001B[0;32m    374\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# map-style\u001B[39;00m\n\u001B[0;32m    375\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m shuffle:\n\u001B[1;32m--> 376\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m \u001B[43mRandomSampler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m    377\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    378\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m SequentialSampler(dataset)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:164\u001B[0m, in \u001B[0;36mRandomSampler.__init__\u001B[1;34m(self, data_source, replacement, num_samples, generator)\u001B[0m\n\u001B[0;32m    159\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    160\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreplacement should be a boolean value, but got replacement=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreplacement\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    161\u001B[0m     )\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 164\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    165\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    166\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T21:33:57.433640Z",
     "start_time": "2024-12-13T21:33:57.429465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_32 = VariableResolutionNetwork(32, pooling=\"mean\")\n",
    "model_48 = VariableResolutionNetwork(48, pooling=\"mean\")\n",
    "model_64 = VariableResolutionNetwork(64, pooling=\"mean\")\n"
   ],
   "id": "82788d8d8ec520ed",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T21:35:17.276476Z",
     "start_time": "2024-12-13T21:35:17.271995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in model_32.parameters():\n",
    "    print(i.size())\n"
   ],
   "id": "5d444b1e9efb06de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 3, 3])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 32, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 32])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T21:35:36.811691Z",
     "start_time": "2024-12-13T21:35:36.808428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in model_48.parameters():\n",
    "    print(i.size())"
   ],
   "id": "694d758c580b9878",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 3, 3])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 3, 3])\n",
      "torch.Size([32])\n",
      "torch.Size([48, 32, 3, 3])\n",
      "torch.Size([48])\n",
      "torch.Size([10, 48])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T22:20:49.707194Z",
     "start_time": "2024-12-13T22:20:49.703523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_total_parameters(model):\n",
    "    final = 0\n",
    "    for i in model.parameters():\n",
    "        result = 1\n",
    "        for j in i.size():\n",
    "            result *= j\n",
    "        final += result\n",
    "    return final"
   ],
   "id": "e46910f0e4c918a5",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T22:21:05.995166Z",
     "start_time": "2024-12-13T22:21:05.990470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = calculate_total_parameters(model_32)\n",
    "a"
   ],
   "id": "19b5b44d5adf2c4c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14666"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T22:21:07.145553Z",
     "start_time": "2024-12-13T22:21:07.142022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "b = calculate_total_parameters(model_48)\n",
    "b"
   ],
   "id": "e41583222b085f18",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19450"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T22:21:08.638356Z",
     "start_time": "2024-12-13T22:21:08.633580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "c = calculate_total_parameters(model_64)\n",
    "c"
   ],
   "id": "319fb8dcd351a131",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24234"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T22:22:19.583411Z",
     "start_time": "2024-12-13T22:22:19.579082Z"
    }
   },
   "cell_type": "code",
   "source": "(a + b + c) / 3",
   "id": "6a63cd56627455ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19450.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aed8c54f747edfb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T20:42:48.353793Z",
     "start_time": "2024-12-13T20:38:49.557215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N_values = [32]\n",
    "\n",
    "# Part 15: Run experiments for global max pooling\n",
    "max_pool_results = experiment(N_values, pooling_type=\"max\", epochs=10, batch_size=32, lr=0.0001)\n",
    "plot_results(max_pool_results, metric=\"val_accuracies\")"
   ],
   "id": "efaf143e88ce59c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with N=32, pooling=max, additional_conv=False\n",
      "Epoch 1/10, Loss: 0.5018, Val Accuracy: 0.8596\n",
      "Epoch 2/10, Loss: 0.4157, Val Accuracy: 0.8596\n",
      "Epoch 3/10, Loss: 0.4147, Val Accuracy: 0.8596\n",
      "Epoch 4/10, Loss: 0.4138, Val Accuracy: 0.8596\n",
      "Epoch 5/10, Loss: 0.4130, Val Accuracy: 0.8596\n",
      "Epoch 6/10, Loss: 0.4129, Val Accuracy: 0.8596\n",
      "Epoch 7/10, Loss: 0.4123, Val Accuracy: 0.8596\n",
      "Epoch 8/10, Loss: 0.4122, Val Accuracy: 0.8596\n",
      "Epoch 9/10, Loss: 0.4119, Val Accuracy: 0.8596\n",
      "Epoch 10/10, Loss: 0.4115, Val Accuracy: 0.8596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T21:31:38.886553Z",
     "start_time": "2024-12-13T21:31:34.320527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 数据路径\n",
    "data_path = \"data/mnist-varres/\"\n",
    "\n",
    "def get_data_loaders(data_dir, batch_size=32):\n",
    "    \"\"\"Prepare data loaders for training, validation, and testing.\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)\n",
    "    test_data = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=transform)\n",
    "\n",
    "    train_size = len(train_data) - 10000\n",
    "    val_size = 10000\n",
    "    traindata, valdata = random_split(train_data, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    trainloader = DataLoader(traindata, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    valloader = DataLoader(valdata, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    testloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    return trainloader, valloader, testloader\n",
    "\n",
    "# 构建网络\n",
    "class VariableResolutionCNN(nn.Module):\n",
    "    def __init__(self, n, num_classes=10, pooling_type='max'):\n",
    "        super(VariableResolutionCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, n, kernel_size=3, stride=1, padding=1)\n",
    "        self.pooling_type = pooling_type\n",
    "        if pooling_type == 'max':\n",
    "            self.global_pool = nn.AdaptiveMaxPool2d(1)  # 全局最大池化\n",
    "        elif pooling_type == 'mean':\n",
    "            self.global_pool = nn.AdaptiveAvgPool2d(1)  # 全局平均池化\n",
    "        self.fc = nn.Linear(n, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)  # 第一次池化\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)  # 第二次池化\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.max_pool2d(x, 2)  # 第三次池化\n",
    "        x = self.global_pool(x)  # 全局池化，映射到固定大小\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 训练函数\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        history.append((epoch_loss, epoch_acc))\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "    return history\n",
    "\n",
    "# 测试函数\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 对比不同输入分辨率和全局池化方法\n",
    "results = []\n",
    "# pools = ['max', 'mean']\n",
    "# n_values = [32, 48, 64]\n",
    "pools = ['max']\n",
    "n_values = [32]\n",
    "trainloader, valloader, testloader = get_data_loaders(data_path, batch_size=32)\n",
    "for pooling in pools:\n",
    "    for n in n_values:\n",
    "        print(f\"Training with {pooling} pooling...\")\n",
    "        model = VariableResolutionCNN(n=n, pooling_type=pooling).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        history = train_model(model, trainloader, criterion, optimizer, num_epochs=10)\n",
    "        test_accuracy = test_model(model, testloader)\n",
    "        results.append({'pooling': pooling, 'test_accuracy': test_accuracy})\n",
    "\n",
    "        # 保存历史记录\n",
    "        history_df = pd.DataFrame(history, columns=['loss', 'accuracy'])\n",
    "        history_df.to_csv(f'results_{pooling}_pooling.csv', index=False)\n",
    "\n",
    "        # 绘制训练曲线\n",
    "        plt.plot(range(1, 11), history_df['accuracy'], label=f'{pooling} pooling')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy Comparison')\n",
    "plt.legend()\n",
    "plt.savefig('pooling_comparison.png')\n",
    "plt.show()\n",
    "\n",
    "# 保存结果\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('pooling_results.csv', index=False)\n",
    "\n",
    "# 打印最终测试结果\n",
    "print(results_df)\n"
   ],
   "id": "d221af0b6b11aeca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with max pooling...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 212, in collate\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 271, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Trying to resize storage that is not resizable\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 118\u001B[0m\n\u001B[0;32m    116\u001B[0m model \u001B[38;5;241m=\u001B[39m VariableResolutionCNN(n\u001B[38;5;241m=\u001B[39mn, pooling_type\u001B[38;5;241m=\u001B[39mpooling)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m    117\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m)\n\u001B[1;32m--> 118\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    119\u001B[0m test_accuracy \u001B[38;5;241m=\u001B[39m test_model(model, testloader)\n\u001B[0;32m    120\u001B[0m results\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpooling\u001B[39m\u001B[38;5;124m'\u001B[39m: pooling, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m: test_accuracy})\n",
      "Cell \u001B[1;32mIn[27], line 71\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_loader, criterion, optimizer, num_epochs)\u001B[0m\n\u001B[0;32m     69\u001B[0m correct \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     70\u001B[0m total \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 71\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m inputs, labels \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m     72\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     73\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1465\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1463\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1464\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[idx]\n\u001B[1;32m-> 1465\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   1489\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[0;32m   1490\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[1;32m-> 1491\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1492\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\_utils.py:715\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    711\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    712\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[0;32m    713\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[0;32m    714\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 715\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 398, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 212, in collate\n    collate(samples, collate_fn_map=collate_fn_map)\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 155, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Jalon\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 271, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Trying to resize storage that is not resizable\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T21:22:14.912811Z",
     "start_time": "2024-12-13T21:22:14.842863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N_values = [32, 48, 64]\n",
    "results_max = experiment(N_values, pooling_type=\"max\", epochs=10)\n",
    "results_mean = experiment(N_values, pooling_type=\"mean\", epochs=10)\n",
    "\n",
    "# 可视化结果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N_list = [result['N'] for result in results_max]\n",
    "accuracy_max = [result['accuracy'] for result in results_max]\n",
    "accuracy_mean = [result['accuracy'] for result in results_mean]\n",
    "\n",
    "plt.plot(N_list, accuracy_max, label=\"Global Max Pool\")\n",
    "plt.plot(N_list, accuracy_mean, label=\"Global Mean Pool\")\n",
    "plt.xlabel(\"N\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy vs N\")\n",
    "plt.show()\n"
   ],
   "id": "754c197cdff3cfbb",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: './mnist-varres/train'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 23\u001B[0m\n\u001B[0;32m     18\u001B[0m transform \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[0;32m     19\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mToTensor()  \u001B[38;5;66;03m# 保持原分辨率，不进行Resize\u001B[39;00m\n\u001B[0;32m     20\u001B[0m ])\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# 加载数据集\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mdatasets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mImageFolder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m datasets\u001B[38;5;241m.\u001B[39mImageFolder(root\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(data_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m), transform\u001B[38;5;241m=\u001B[39mtransform)\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# 数据加载器\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001B[0m, in \u001B[0;36mImageFolder.__init__\u001B[1;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001B[0m\n\u001B[0;32m    319\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    320\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    321\u001B[0m     root: Union[\u001B[38;5;28mstr\u001B[39m, Path],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    326\u001B[0m     allow_empty: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    327\u001B[0m ):\n\u001B[1;32m--> 328\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    329\u001B[0m \u001B[43m        \u001B[49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    330\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    331\u001B[0m \u001B[43m        \u001B[49m\u001B[43mIMG_EXTENSIONS\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    332\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    333\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget_transform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_transform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    334\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_valid_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    335\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_empty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_empty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    336\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    337\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimgs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:149\u001B[0m, in \u001B[0;36mDatasetFolder.__init__\u001B[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    140\u001B[0m     root: Union[\u001B[38;5;28mstr\u001B[39m, Path],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    146\u001B[0m     allow_empty: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    147\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(root, transform\u001B[38;5;241m=\u001B[39mtransform, target_transform\u001B[38;5;241m=\u001B[39mtarget_transform)\n\u001B[1;32m--> 149\u001B[0m     classes, class_to_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind_classes\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroot\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    150\u001B[0m     samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmake_dataset(\n\u001B[0;32m    151\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot,\n\u001B[0;32m    152\u001B[0m         class_to_idx\u001B[38;5;241m=\u001B[39mclass_to_idx,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    155\u001B[0m         allow_empty\u001B[38;5;241m=\u001B[39mallow_empty,\n\u001B[0;32m    156\u001B[0m     )\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader \u001B[38;5;241m=\u001B[39m loader\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:234\u001B[0m, in \u001B[0;36mDatasetFolder.find_classes\u001B[1;34m(self, directory)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_classes\u001B[39m(\u001B[38;5;28mself\u001B[39m, directory: Union[\u001B[38;5;28mstr\u001B[39m, Path]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[List[\u001B[38;5;28mstr\u001B[39m], Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mint\u001B[39m]]:\n\u001B[0;32m    208\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001B[39;00m\n\u001B[0;32m    209\u001B[0m \n\u001B[0;32m    210\u001B[0m \u001B[38;5;124;03m        directory/\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001B[39;00m\n\u001B[0;32m    233\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 234\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfind_classes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepLearning_asg3\\Lib\\site-packages\\torchvision\\datasets\\folder.py:41\u001B[0m, in \u001B[0;36mfind_classes\u001B[1;34m(directory)\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_classes\u001B[39m(directory: Union[\u001B[38;5;28mstr\u001B[39m, Path]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[List[\u001B[38;5;28mstr\u001B[39m], Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mint\u001B[39m]]:\n\u001B[0;32m     37\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001B[39;00m\n\u001B[0;32m     38\u001B[0m \n\u001B[0;32m     39\u001B[0m \u001B[38;5;124;03m    See :class:`DatasetFolder` for details.\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 41\u001B[0m     classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(entry\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m entry \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscandir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m entry\u001B[38;5;241m.\u001B[39mis_dir())\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m classes:\n\u001B[0;32m     43\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find any class folder in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdirectory\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] 系统找不到指定的路径。: './mnist-varres/train'"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f1feb7f3ce003649"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
